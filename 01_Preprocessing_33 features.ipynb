{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cf45ad31",
      "metadata": {},
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8374pvvBxZE_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8374pvvBxZE_",
        "outputId": "4452a141-315c-407d-8dd4-d6472ee99a4b"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "ROOT = \"/content/drive/25-2-Machine-Learning-Onions/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4f8f244",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4f8f244",
        "outputId": "f9185786-2a72-4e2d-f7dc-2405c2385347"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# ==============================\n",
        "# 0. ê¸°ë³¸ ì„¤ì • & ë°ì´í„° ë¡œë“œ\n",
        "# ==============================\n",
        "USE_SUBLABEL = False\n",
        "URL_PER_SITE = 10\n",
        "TOTAL_URLS   = 950\n",
        "\n",
        "print(\"Loading datafile...\")\n",
        "with open(f\"{ROOT}data/raw/mon_standard.pkl\", \"rb\") as fi:\n",
        "    data = pickle.load(fi)\n",
        "\n",
        "# X_time : timestamp ì‹œí€€ìŠ¤ (abs(c))\n",
        "# X_dir  : ë°©í–¥ ì‹œí€€ìŠ¤ (+1/-1)\n",
        "# X_size : ê³ ì • í¬ê¸° 512 ê¸°ë°˜ size ì‹œí€€ìŠ¤ (+512/-512)\n",
        "X_time = []\n",
        "X_dir  = []\n",
        "X_size = []\n",
        "y = []\n",
        "\n",
        "for i in range(TOTAL_URLS):\n",
        "    if USE_SUBLABEL:\n",
        "        label = i\n",
        "    else:\n",
        "        label = i // URL_PER_SITE  # ê°™ì€ ì‚¬ì´íŠ¸ = ê°™ì€ ë ˆì´ë¸”\n",
        "\n",
        "    for sample in data[i]:\n",
        "        time_seq = []\n",
        "        dir_seq  = []\n",
        "        size_seq = []\n",
        "\n",
        "        for c in sample:\n",
        "            dr = 1 if c > 0 else -1     # ë°©í–¥\n",
        "            time_seq.append(abs(c))     # ì‹œê°„ ì •ë³´\n",
        "            dir_seq.append(dr)          # ë°©í–¥ ì •ë³´\n",
        "            size_seq.append(dr * 512.0) # ğŸ”µ ê³ ì • í¬ê¸° 512 ì ìš©\n",
        "\n",
        "        X_time.append(time_seq)\n",
        "        X_dir.append(dir_seq)\n",
        "        X_size.append(size_seq)\n",
        "        y.append(label)\n",
        "\n",
        "print(\"Total samples:\", len(y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b572ee52",
      "metadata": {
        "id": "b572ee52"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# 1. IAT/ë°©í–¥/Burst ê¸°ë°˜ 33ì°¨ì› feature\n",
        "# ==============================\n",
        "def extract_features(time_seq, dir_seq):\n",
        "    \"\"\"\n",
        "    time_seq : list/array of timestamps        (ì˜ˆ: [0.0, 0.2, 0.25, ...])\n",
        "    dir_seq  : list/array of direction (+1/-1) (ì˜ˆ: [ 1,  -1,   -1,  ...])\n",
        "\n",
        "    ë°˜í™˜: ê¸¸ì´ 33ì˜ feature ë²¡í„°\n",
        "    \"\"\"\n",
        "\n",
        "    t = np.asarray(time_seq, dtype=float)\n",
        "    d = np.sign(np.asarray(dir_seq, dtype=float))  # +1(ì†¡ì‹ ), -1(ìˆ˜ì‹ )\n",
        "\n",
        "    # íŒ¨í‚·ì´ ë„ˆë¬´ ì ì„ ë•Œ ë°©ì–´ì  ì²˜ë¦¬\n",
        "    if len(t) < 2:\n",
        "        return np.zeros(33, dtype=float)\n",
        "\n",
        "    # ---------- [A] IAT ê¸°ë°˜ feature (5ê°œ) ----------\n",
        "    iat = np.diff(t)\n",
        "    mean_iat   = float(np.mean(iat))\n",
        "    std_iat    = float(np.std(iat))\n",
        "    median_iat = float(np.median(iat))\n",
        "    q25_iat, q75_iat = np.quantile(iat, [0.25, 0.75])\n",
        "\n",
        "    # ---------- [B] ì„¸ì…˜ ìš”ì•½ feature (4ê°œ) ----------\n",
        "    n_packets = float(len(t))\n",
        "    num_out = float((d > 0).sum())\n",
        "    num_in  = float((d < 0).sum())\n",
        "\n",
        "    ratio_out     = num_out / n_packets          # ì „ì²´ ì¤‘ outgoing ë¹„ìœ¨\n",
        "    switch_count  = float(np.sum(np.diff(d) != 0))\n",
        "    duration      = float(t[-1] - t[0])\n",
        "\n",
        "    # ---------- [C] Burst ê¸°ë°˜ feature (5ê°œ) ----------\n",
        "    bursts = []\n",
        "    current_dir = d[0]\n",
        "    count = 1\n",
        "    for val in d[1:]:\n",
        "        if val == current_dir:\n",
        "            count += 1\n",
        "        else:\n",
        "            bursts.append((current_dir, count))\n",
        "            current_dir, count = val, 1\n",
        "    bursts.append((current_dir, count))\n",
        "\n",
        "    burst_lens = np.array([b[1] for b in bursts], dtype=float)\n",
        "    burst_dirs = np.array([b[0] for b in bursts], dtype=float)\n",
        "\n",
        "    burst_count    = float(len(burst_lens))\n",
        "    burst_mean     = float(burst_lens.mean()) if len(burst_lens) else 0.0\n",
        "    burst_std      = float(burst_lens.std())  if len(burst_lens) else 0.0\n",
        "    burst_max      = float(burst_lens.max())  if len(burst_lens) else 0.0\n",
        "    burst_ratio_in = float((burst_dirs < 0).mean()) if len(burst_dirs) else 0.0\n",
        "\n",
        "    # ---------- [D] ì¶”ê°€ feature (5ê°œ) ----------\n",
        "    frac_in = num_in / n_packets    # incoming ë¹„ìœ¨ (outgoing ë¹„ìœ¨ì€ ratio_out)\n",
        "\n",
        "    # ì²« 30ê°œ íŒ¨í‚· ê¸°ì¤€ í†µê³„\n",
        "    first_k = min(30, len(d))\n",
        "    d_first = d[:first_k]\n",
        "    in_first30  = float((d_first < 0).sum())\n",
        "    out_first30 = float((d_first > 0).sum())\n",
        "\n",
        "    # ---------- [E] ì²« 30ê°œ íŒ¨í‚· ê¸°ì¤€ í™•ì¥ feature (14ê°œ) ----------\n",
        "\n",
        "    # [E1] IAT (first 30)\n",
        "    t_first = t[:first_k]\n",
        "    if len(t_first) >= 2:\n",
        "        iat_first = np.diff(t_first)\n",
        "        mean_iat_first30   = float(np.mean(iat_first))\n",
        "        std_iat_first30    = float(np.std(iat_first))\n",
        "        median_iat_first30 = float(np.median(iat_first))\n",
        "        q25_iat_first30, q75_iat_first30 = np.quantile(iat_first, [0.25, 0.75])\n",
        "    else:\n",
        "        mean_iat_first30 = std_iat_first30 = 0.0\n",
        "        median_iat_first30 = q25_iat_first30 = q75_iat_first30 = 0.0\n",
        "\n",
        "    # [E2] ì„¸ì…˜ ìš”ì•½ (first 30, n_packets ì œì™¸)\n",
        "    ratio_out_first30 = out_first30 / float(first_k)\n",
        "    switch_count_first30 = float(np.sum(np.diff(d_first) != 0)) if first_k > 1 else 0.0\n",
        "    duration_first30 = float(t_first[-1] - t_first[0]) if first_k > 1 else 0.0\n",
        "\n",
        "    # [E3] Burst (first 30)\n",
        "    bursts_first = []\n",
        "    current_dir = d_first[0]\n",
        "    count = 1\n",
        "    for val in d_first[1:]:\n",
        "        if val == current_dir:\n",
        "            count += 1\n",
        "        else:\n",
        "            bursts_first.append((current_dir, count))\n",
        "            current_dir, count = val, 1\n",
        "    bursts_first.append((current_dir, count))\n",
        "\n",
        "    burst_lens_first = np.array([b[1] for b in bursts_first], dtype=float)\n",
        "    burst_dirs_first = np.array([b[0] for b in bursts_first], dtype=float)\n",
        "\n",
        "    burst_count_first30    = float(len(burst_lens_first))\n",
        "    burst_mean_first30     = float(burst_lens_first.mean()) if len(burst_lens_first) else 0.0\n",
        "    burst_std_first30      = float(burst_lens_first.std())  if len(burst_lens_first) else 0.0\n",
        "    burst_max_first30      = float(burst_lens_first.max())  if len(burst_lens_first) else 0.0\n",
        "    burst_ratio_in_first30 = float((burst_dirs_first < 0).mean()) if len(burst_dirs_first) else 0.0\n",
        "\n",
        "    # [E4] ë°©í–¥ ë¹„ìœ¨ (first 30)\n",
        "    frac_in_first30 = in_first30 / float(first_k)\n",
        "\n",
        " # ---------- ìµœì¢… feature ë²¡í„° (ì´ 33ê°œ) ----------\n",
        "    return np.array([\n",
        "        # [A] IAT 5ê°œ (ì „ì²´)\n",
        "        mean_iat, std_iat, median_iat, q25_iat, q75_iat,\n",
        "        # [B] ì„¸ì…˜ ìš”ì•½ 4ê°œ (ì „ì²´)\n",
        "        ratio_out, switch_count, duration, n_packets,\n",
        "        # [C] Burst 5ê°œ (ì „ì²´)\n",
        "        burst_count, burst_mean, burst_std, burst_max, burst_ratio_in,\n",
        "        # [D] ì¶”ê°€ 5ê°œ (ì „ì²´ + ê¸°ì¡´ first30 count)\n",
        "        num_in, num_out, frac_in, in_first30, out_first30,\n",
        "\n",
        "        # [E1] IAT 5ê°œ (first 30)\n",
        "        mean_iat_first30, std_iat_first30, median_iat_first30,\n",
        "        q25_iat_first30, q75_iat_first30,\n",
        "        # [E2] ì„¸ì…˜ ìš”ì•½ 3ê°œ (first 30)\n",
        "        ratio_out_first30, switch_count_first30, duration_first30,\n",
        "        # [E3] Burst 5ê°œ (first 30)\n",
        "        burst_count_first30, burst_mean_first30, burst_std_first30,\n",
        "        burst_max_first30, burst_ratio_in_first30,\n",
        "        # [E4] ë°©í–¥ ë¹„ìœ¨ 1ê°œ (first 30)\n",
        "        frac_in_first30\n",
        "    ], dtype=float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a922567a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a922567a",
        "outputId": "167b0efb-23fc-4ead-b1a2-1ef88d190682"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# 2. ëª¨ë“  monitored ì„¸ì…˜ì— ëŒ€í•´ feature í–‰ë ¬ ìƒì„±\n",
        "# ==============================\n",
        "X_feat_monitored = np.vstack([\n",
        "    extract_features(t, d)\n",
        "    for t, d in zip(X_time, X_dir)\n",
        "])\n",
        "y_monitored = np.asarray(y, dtype=int)\n",
        "\n",
        "print(\"X_feat_monitored.shape:\", X_feat_monitored.shape)  # (N_mon, 19)\n",
        "print(\"y_monitored.shape:\", y_monitored.shape)\n",
        "\n",
        "# ==============================\n",
        "# 3. feature ì´ë¦„ ì •ì˜\n",
        "# ==============================\n",
        "feature_names = [\n",
        "    # [A] IAT (ì „ì²´)\n",
        "    \"mean_iat\", \"std_iat\", \"median_iat\", \"q25_iat\", \"q75_iat\",\n",
        "    # [B] ì„¸ì…˜ ìš”ì•½ (ì „ì²´)\n",
        "    \"ratio_out\", \"switch_count\", \"duration\", \"n_packets\",\n",
        "    # [C] Burst (ì „ì²´)\n",
        "    \"burst_count\", \"burst_mean\", \"burst_std\", \"burst_max\", \"burst_ratio_in\",\n",
        "    # [D] ì¶”ê°€ (ì „ì²´ + first30 count)\n",
        "    \"num_in\", \"num_out\", \"frac_in\", \"in_first30\", \"out_first30\",\n",
        "\n",
        "    # [E1] IAT (first 30)\n",
        "    \"mean_iat_first30\", \"std_iat_first30\", \"median_iat_first30\",\n",
        "    \"q25_iat_first30\", \"q75_iat_first30\",\n",
        "    # [E2] ì„¸ì…˜ ìš”ì•½ (first 30)\n",
        "    \"ratio_out_first30\", \"switch_count_first30\", \"duration_first30\",\n",
        "    # [E3] Burst (first 30)\n",
        "    \"burst_count_first30\", \"burst_mean_first30\", \"burst_std_first30\",\n",
        "    \"burst_max_first30\", \"burst_ratio_in_first30\",\n",
        "    # [E4] ë°©í–¥ ë¹„ìœ¨ (first 30)\n",
        "    \"frac_in_first30\",\n",
        "]\n",
        "print(\"len(feature_names):\", len(feature_names))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ab98692",
      "metadata": {
        "id": "4ab98692"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1ï¸âƒ£ ë¨¼ì € train+val ê³¼ testë¥¼ ë¶„ë¦¬\n",
        "X_train_val, X_test_close, y_train_val, y_test_close = train_test_split(\n",
        "    X_feat_monitored, y, test_size=0.15, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 2ï¸âƒ£ ë‹¤ìŒìœ¼ë¡œ train ê³¼ val ë¶„ë¦¬\n",
        "val_size = 0.15 / (1 - 0.15)\n",
        "X_train_close, X_val_close, y_train_close, y_val_close = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=val_size, random_state=42, stratify=y_train_val\n",
        ")\n",
        "\n",
        "\n",
        "# 3ï¸âƒ£ ìŠ¤ì¼€ì¼ë§\n",
        "scaler = StandardScaler()\n",
        "X_train_close_scaled = scaler.fit_transform(X_train_close)\n",
        "X_val_close_scaled  = scaler.transform(X_val_close)\n",
        "X_test_close_scaled = scaler.transform(X_test_close)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb7f61de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "id": "cb7f61de",
        "outputId": "56ca5702-09fa-46b9-85d7-2603742b287f"
      },
      "outputs": [],
      "source": [
        "# ==== ê³µí†µ: ì €ì¥/ë¯¸ë¦¬ë³´ê¸° ====\n",
        "import pickle, numpy as np, pandas as pd\n",
        "\n",
        "def save_pickle(path, obj):\n",
        "    with open(path, \"wb\") as f:\n",
        "        pickle.dump(obj, f)\n",
        "\n",
        "def load_pickle(path):\n",
        "    with open(path, \"rb\") as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "def head_pickle(path, n=5):\n",
        "    d = load_pickle(path)\n",
        "    X, y, cols = d[\"X\"], d[\"y\"], d[\"feature_names\"]\n",
        "    df = pd.DataFrame(X, columns=cols)\n",
        "    df[\"label\"] = y\n",
        "    print(f\"=== {path} === shape={X.shape}, labels={y.shape}\")\n",
        "    display(df.head(n))\n",
        "    return d\n",
        "\n",
        "\n",
        "\n",
        "# ==== dtype ì •ë¦¬ (ê¶Œì¥) ====\n",
        "X_train_close_scaled = X_train_close_scaled.astype(\"float32\")\n",
        "X_val_close_scaled   = X_val_close_scaled.astype(\"float32\")\n",
        "X_test_close_scaled  = X_test_close_scaled.astype(\"float32\")\n",
        "y_train_close = np.asarray(y_train_close, dtype=\"int64\")\n",
        "y_val_close   = np.asarray(y_val_close,   dtype=\"int64\")\n",
        "y_test_close  = np.asarray(y_test_close,  dtype=\"int64\")\n",
        "\n",
        "# ==== ê°œë³„ íŒŒì¼ ì €ì¥ (dict í¬ë§·) ====\n",
        "base = {\"feature_names\": feature_names, \"scaler\": scaler}\n",
        "SAVE_DIR = f\"{ROOT}data/preprocessed/\"\n",
        "\n",
        "save_pickle(f\"{SAVE_DIR}close_train_33.pkl\", {**base, \"X\": X_train_close_scaled, \"y\": y_train_close})\n",
        "save_pickle(f\"{SAVE_DIR}close_val_33.pkl\",   {**base, \"X\": X_val_close_scaled,   \"y\": y_val_close})\n",
        "save_pickle(f\"{SAVE_DIR}close_test_33.pkl\",  {**base, \"X\": X_test_close_scaled,  \"y\": y_test_close})\n",
        "print(\"Saved: close_train_33.pkl / close_val_33.pkl / close_test_33.pkl\")\n",
        "\n",
        "_ = head_pickle(f\"{SAVE_DIR}close_train_33.pkl\", n=5)\n",
        "_ = head_pickle(f\"{SAVE_DIR}close_val_33.pkl\",   n=5)\n",
        "_ = head_pickle(f\"{SAVE_DIR}close_test_33.pkl\",  n=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dae93ed2",
      "metadata": {
        "id": "dae93ed2"
      },
      "outputs": [],
      "source": [
        "y_mon_train_bin = np.ones(len(y_train_close), dtype=int)   # (N_train,)\n",
        "y_mon_val_bin = np.ones(len(y_val_close), dtype=int)\n",
        "y_mon_test_bin = np.ones(len(y_test_close), dtype=int)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79ec376c",
      "metadata": {
        "id": "79ec376c"
      },
      "source": [
        "================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5bc9a17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5bc9a17",
        "outputId": "bbc4bb8c-4819-4de1-838c-00503eed8297"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "TOTAL_URLS = 10000  # total number in the dataset\n",
        "\n",
        "# Load 10,000 unmon pickle file\n",
        "print(\"Loading datafile...\")\n",
        "with open(f\"{ROOT}data/raw/unmon_standard10.pkl\", 'rb') as f:  # Path to unmon_standard10.pkl in Colab\n",
        "    x = pickle.load(f)\n",
        "\n",
        "size = len(x)\n",
        "print(f'Total samples: {size}')\n",
        "\n",
        "X1 = [] # Array to store instances (timestamps) - 10,000 instances, e.g., [[0.0, 0.5, 3.4, ...], [0.0, 4.5, ...], [0.0, 1.5, ...], ... [... ,45.8]]\n",
        "X2 = [] # Array to store instances (direction*size) - size information\n",
        "\n",
        "for i in range(TOTAL_URLS):\n",
        "    size_seq = []\n",
        "    time_seq = []\n",
        "    for c in x[i]:\n",
        "        dr = 1 if c > 0 else -1\n",
        "        time_seq.append(abs(c))\n",
        "        size_seq.append(dr * 512) # In the pickle file, there is no size information, so the conversion code is set to multiply by 512 uniformly.\n",
        "    X1.append(time_seq)\n",
        "    X2.append(size_seq)\n",
        "\n",
        "print(len(X1)) # Print the length of X1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ae663b3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ae663b3",
        "outputId": "176ae8a9-391c-483e-b4d2-4621dbd63827"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# =========================================\n",
        "# 1) ë°©í–¥ ì •ê·œí™” (+1 / -1)\n",
        "#    X2 : ê° ì„¸ì…˜ë³„ ë°©í–¥/size ì‹œí€€ìŠ¤ (ex: dr*512)\n",
        "#         â†’ signë§Œ ì“°ë©´ ë°©í–¥ ì‹œí€€ìŠ¤ë¡œ ì“¸ ìˆ˜ ìˆìŒ\n",
        "# =========================================\n",
        "X2_bin = [np.sign(np.asarray(seq, float)).astype(int).tolist() for seq in X2]\n",
        "\n",
        "# =========================================\n",
        "# 2) ëª¨ë“  unmon ì„¸ì…˜ì— ëŒ€í•´ monitoredì™€ ê°™ì€ feature (33ê°œ) ìƒì„±\n",
        "#    X1 : time_seq ë¦¬ìŠ¤íŠ¸, X2_bin : direction(+1/-1) ë¦¬ìŠ¤íŠ¸\n",
        "# =========================================\n",
        "X_feat_unmon = np.vstack([\n",
        "    extract_features(t, d)\n",
        "    for t, d in zip(X1, X2_bin)\n",
        "])\n",
        "print(\"X_feat_unmon.shape:\", X_feat_unmon.shape)  # (N_unmon, 33)\n",
        "\n",
        "N_unmon = X_feat_unmon.shape[0]\n",
        "\n",
        "# ë¼ë²¨ë„ N_unmonì— ë§ì¶° ìƒì„±\n",
        "y_unmon_true = -np.ones(N_unmon, dtype=int)\n",
        "y_unmon_bin  = -np.ones(N_unmon, dtype=int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bbe0309",
      "metadata": {
        "id": "7bbe0309"
      },
      "outputs": [],
      "source": [
        "# =========================================\n",
        "# 4) unmon ë°ì´í„° train/val/test split\n",
        "# =========================================\n",
        "X_unmon_train_val, X_unmon_test, y_unmon_train_val, y_unmon_test = train_test_split(\n",
        "    X_feat_unmon,\n",
        "    y_unmon_true,\n",
        "    test_size=0.15,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "val_size = 0.15 / (1 - 0.15)\n",
        "\n",
        "X_unmon_train, X_unmon_val, y_unmon_train, y_unmon_val = train_test_split(\n",
        "    X_unmon_train_val,\n",
        "    y_unmon_train_val,\n",
        "    test_size=val_size,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "# binary ë¼ë²¨ (í˜•íƒœë§Œ ë§ì¶°ì£¼ê¸°)\n",
        "y_unmon_train_bin = -np.ones_like(y_unmon_train, dtype=int)\n",
        "y_unmon_val_bin   = -np.ones_like(y_unmon_val,   dtype=int)\n",
        "y_unmon_test_bin  = -np.ones_like(y_unmon_test,  dtype=int)\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# 5) open-world ë°ì´í„° êµ¬ì„± (monitored + unmonitored)\n",
        "# =========================================\n",
        "# ì—¬ê¸°ì„œ X_train_close, X_val_close, X_test_close ëŠ”\n",
        "# \"monitored feature 33ì°¨ì›ì§œë¦¬ (ìŠ¤ì¼€ì¼ë§ ì „)\" ì´ë¼ê³  ê°€ì •\n",
        "# y_mon_train_bin ë“±ì€ monitoredì— ëŒ€í•´ +1 / -1 ë¼ë²¨ë§ í•´ë‘” ê²ƒ\n",
        "\n",
        "# ğŸ”µ open-world train (raw)\n",
        "X_train_open_raw = np.concatenate([X_train_close, X_unmon_train], axis=0)\n",
        "y_train_open_true = np.concatenate([y_train_close, y_unmon_train])\n",
        "y_train_open_bin  = np.concatenate([y_mon_train_bin, y_unmon_train_bin])\n",
        "\n",
        "# ğŸŸ£ open-world val (raw)\n",
        "X_val_open_raw = np.concatenate([X_val_close, X_unmon_val], axis=0)\n",
        "y_val_open_true = np.concatenate([y_val_close, y_unmon_val])\n",
        "y_val_open_bin  = np.concatenate([y_mon_val_bin, y_unmon_val_bin])\n",
        "\n",
        "# ğŸ”´ open-world test (raw)\n",
        "X_test_open_raw = np.concatenate([X_test_close, X_unmon_test], axis=0)\n",
        "y_test_open_true = np.concatenate([y_test_close, y_unmon_test])\n",
        "y_test_open_bin  = np.concatenate([y_mon_test_bin, y_unmon_test_bin])\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# 6) ìŠ¤ì¼€ì¼ë§\n",
        "# =========================================\n",
        "scaler = StandardScaler()\n",
        "X_train_open = scaler.fit_transform(X_train_open_raw)\n",
        "X_val_open   = scaler.transform(X_val_open_raw)\n",
        "X_test_open  = scaler.transform(X_test_open_raw)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f32e6099",
      "metadata": {
        "id": "f32e6099"
      },
      "outputs": [],
      "source": [
        "save_pickle(f\"{SAVE_DIR}open_train_33.pkl\", {\n",
        "    \"X\": X_train_open,\n",
        "    \"y_true\": y_train_open_true,\n",
        "    \"y_binary\": y_train_open_bin,\n",
        "    \"feature_names\": feature_names,\n",
        "    \"scaler\": scaler,   # ë‚˜ì¤‘ì— inverse_transform ë“± ê°€ëŠ¥\n",
        "})\n",
        "\n",
        "save_pickle(f\"{SAVE_DIR}open_val_33.pkl\", {\n",
        "    \"X\": X_val_open,\n",
        "    \"y_true\": y_val_open_true,\n",
        "    \"y_binary\": y_val_open_bin,\n",
        "    \"feature_names\": feature_names,\n",
        "})\n",
        "\n",
        "save_pickle(f\"{SAVE_DIR}open_test_33.pkl\", {\n",
        "    \"X\": X_test_open,\n",
        "    \"y_true\": y_test_open_true,\n",
        "    \"y_binary\": y_test_open_bin,\n",
        "    \"feature_names\": feature_names,\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98df022a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98df022a",
        "outputId": "d8562a43-e258-4b5a-8e67-bc8dbe2a8664"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "def head_pickle_2(path, n=5):\n",
        "    with open(path, \"rb\") as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    X = data[\"X\"]\n",
        "    feature_names = data.get(\"feature_names\", None)\n",
        "\n",
        "    print(f\"\\n=== {path} === shape={X.shape}\")\n",
        "\n",
        "    if feature_names is not None and len(feature_names) == X.shape[1]:\n",
        "        df = pd.DataFrame(X[:], columns=feature_names)\n",
        "    else:\n",
        "        df = pd.DataFrame(X[:])\n",
        "\n",
        "\n",
        "    # ğŸ”¹ ë‘ labelì„ ëª¨ë‘ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€\n",
        "    if \"y_true\" in data:\n",
        "        df[\"y_true\"] = data[\"y_true\"][:]\n",
        "    if \"y_binary\" in data:\n",
        "        df[\"y_binary\"] = data[\"y_binary\"][:]\n",
        "\n",
        "    print(df.sample())\n",
        "    return data\n",
        "\n",
        "\n",
        "_ = head_pickle_2(f\"{SAVE_DIR}open_train_33.pkl\", n=5)\n",
        "_ = head_pickle_2(f\"{SAVE_DIR}open_val_33.pkl\", n=5)\n",
        "_ = head_pickle_2(f\"{SAVE_DIR}open_test_33.pkl\", n=100)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V6E1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.12.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
